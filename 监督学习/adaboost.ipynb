{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X=np.arange(10).reshape(-1,1)\n",
    "y=np.array([1,1,1,-1,-1,-1,1,1,1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
      "---  simpleClf----- 2.5 False\n",
      "0.30000000000000004\n",
      "0.30000000000000004\n",
      "\n",
      "[0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.16666667 0.16666667 0.16666667 0.07142857]\n",
      "---  simpleClf----- 8.5 False\n",
      "0.21428571428571427\n",
      "0.21428571428571427\n",
      "\n",
      "[0.04545455 0.04545455 0.04545455 0.16666667 0.16666667 0.16666667\n",
      " 0.10606061 0.10606061 0.10606061 0.04545455]\n",
      "---  simpleClf----- 5.5 True\n",
      "0.18181818181818188\n",
      "0.18181818181818188\n",
      "[ 1.  1.  1. -1. -1. -1.  1.  1.  1. -1.]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# 李航统计学习方法代码实现\n",
    "import copy\n",
    "class SimpleClf:\n",
    "    def __init__(self):\n",
    "        self.split_x=[]\n",
    "        self.best_split_x=None\n",
    "        self.reverse=False\n",
    "        pass\n",
    "    def fit(self,X,y,w):\n",
    "        best_loss=1e10 \n",
    "        best_split_x=-1\n",
    "        for i in range(len(X)-1):\n",
    "            \n",
    "            split_x=(X[i]+X[i+1])/2\n",
    "            self.split_x.append(float(split_x))\n",
    "        for split_x in self.split_x:\n",
    "            pre_y=self.__predict_by_split_x(X,split_x)\n",
    "            loss=w.dot(pre_y!=y)\n",
    "            if best_loss >loss:\n",
    "                best_loss=loss\n",
    "                self.best_split_x=split_x \n",
    "        for split_x in self.split_x:\n",
    "            pre_y=self.__predict_by_split_x_reverse(X,split_x)\n",
    "            loss=w.dot(pre_y!=y)\n",
    "            if best_loss >loss:\n",
    "                best_loss=loss\n",
    "                self.reverse=True\n",
    "                self.best_split_x=split_x  \n",
    "        print(\"---  simpleClf-----\",self.best_split_x,self.reverse)\n",
    "        pass\n",
    "    def score(self,X,y):\n",
    "        pre_y=self.predict(X)\n",
    "        return sum(pre_y==y)/len(y)\n",
    "    def predict(self,X):\n",
    "        pre_y=[]\n",
    "        for x in X:\n",
    "            if self.reverse:\n",
    "                if x <self.best_split_x:\n",
    "                    pre_y.append(-1)\n",
    "                else :\n",
    "                    pre_y.append(1)\n",
    "            else:\n",
    "                if x <self.best_split_x:\n",
    "                    pre_y.append(1)\n",
    "                else :\n",
    "                    pre_y.append(-1)\n",
    "        return np.array(pre_y)\n",
    "    def __predict_by_split_x(self,X,split_x):\n",
    "        pre_y=[]\n",
    "        for x in X:\n",
    "            if x <split_x:\n",
    "                pre_y.append(1)\n",
    "            else :\n",
    "                pre_y.append(-1)\n",
    "        return np.array(pre_y)\n",
    "            \n",
    "    def __predict_by_split_x_reverse(self,X,split_x):\n",
    "        pre_y=[]\n",
    "        for x in X:\n",
    "            if x >split_x:\n",
    "                pre_y.append(1)\n",
    "            else :\n",
    "                pre_y.append(-1)\n",
    "        return np.array(pre_y)\n",
    "    \n",
    "class AdaBoost:\n",
    "    def __init__(self,base_clf,max_iter=10,learning_rate=1):\n",
    "        self.max_iter=max_iter;\n",
    "        self.base_clf=base_clf\n",
    "        self.clfs=[]\n",
    "        self.alphas=[]\n",
    "        self.f=None\n",
    "        self.learning_rate=learning_rate\n",
    "        pass\n",
    "    def fit(self,X,y):\n",
    "        w=np.ones(len(y))/len(y)\n",
    "        for iter_i in range(self.max_iter):\n",
    "            base_clf=SimpleClf()\n",
    "            print(w)\n",
    "            base_clf.fit(X,y,w)\n",
    "            pre_y=base_clf.predict(X)\n",
    "          \n",
    "            print(w.dot((pre_y!=y).astype('int')))\n",
    "            e_i=w.dot((pre_y!=y).astype('int'))\n",
    "            print(e_i)\n",
    "            alpha_i= 0.5 * np.log((1-e_i)/e_i)\n",
    "            pre_y=base_clf.predict(X)\n",
    "            for i in range(len(w)):\n",
    "                w[i]=w[i]*np.exp(-alpha_i*y[i]*pre_y[i])\n",
    "            w=1/sum(w) *w\n",
    "            self.clfs.append(base_clf)\n",
    "            self.alphas.append(alpha_i)\n",
    "            if self.__train_score(X,y)==1:\n",
    "                break\n",
    "            print()\n",
    "            \n",
    "        pass\n",
    "    def score(self,X,y):\n",
    "        \n",
    "        return self.__train_score(X,y)\n",
    "    def __train_score(self,X,y):\n",
    "        pre_y=self.__train_predict(X)\n",
    "        return sum(pre_y==y)/len(y)\n",
    "    def __train_score_error(self,X,y):\n",
    "        pre_y=self.__train_predict(X)\n",
    "        return sum(pre_y==y)/len(y)\n",
    "    def __train_predict(self,X):\n",
    "        pre_y=np.zeros(len(X))\n",
    "        for i in range(len(self.alphas)):\n",
    "            pre_y+=self.learning_rate*self.clfs[i].predict(X)*self.alphas[i]\n",
    "        pre_y[pre_y>0]=1\n",
    "        pre_y[pre_y<=0]=-1\n",
    "        return pre_y \n",
    "    def predict(self,X):\n",
    "        return self.__train_predict(X)\n",
    "#         for x in X:\n",
    "#             for clf in self.clfs:\n",
    "#                 print(clf.split_x)\n",
    "        \n",
    "        \n",
    "            \n",
    "    \n",
    "    \n",
    "# clf = SimpleClf();\n",
    "# w=np.ones(len(y))/len(y)\n",
    "# clf.fit(X,y,w)\n",
    "# clf.score(X,y)   \n",
    "ada = AdaBoost(SimpleClf(),learning_rate=0.1)\n",
    "ada.fit(X,y)\n",
    "print(ada.predict(X))\n",
    "print(ada.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn\n",
    "bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         algorithm=\"SAMME\",\n",
    "                        n_estimators=10)\n",
    "bdt.fit(X, y)\n",
    "bdt.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
